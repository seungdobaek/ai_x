{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "418393bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.container{width:90% !important;}\n",
       "div.cell.code_cell.rendered{width:100%;}\n",
       "div.input_prompt{padding:0px;}\n",
       "div.CodeMirror {font-family:Consolas; font-size:12pt;}\n",
       "div.text_cell_render.rendered_html{font size:12pt;}\n",
       "div.output {font-size:12pt; font-weight:bold;}\n",
       "div.input{font-family:Consolas; font-size:12pt;}\n",
       "div.prompt {min width:70px;}\n",
       "div#toc-wrapper {padding-top:120px;}\n",
       "div.text_cell_render ul li{font-size:12pt;padding:5px;}\n",
       "table.dataframe {font-size:12px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "div.container{width:90% !important;}\n",
    "div.cell.code_cell.rendered{width:100%;}\n",
    "div.input_prompt{padding:0px;}\n",
    "div.CodeMirror {font-family:Consolas; font-size:12pt;}\n",
    "div.text_cell_render.rendered_html{font size:12pt;}\n",
    "div.output {font-size:12pt; font-weight:bold;}\n",
    "div.input{font-family:Consolas; font-size:12pt;}\n",
    "div.prompt {min width:70px;}\n",
    "div#toc-wrapper {padding-top:120px;}\n",
    "div.text_cell_render ul li{font-size:12pt;padding:5px;}\n",
    "table.dataframe {font-size:12px;}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d993bb",
   "metadata": {},
   "source": [
    "<font size='6' color='red'><b>ch1 허깅페이스</b></font>\n",
    "- Inference API 이용 : 모델의 결과를 server에서\n",
    "- pipeline() 이용 : 모델을 다운로드 받아 모델의 결과를 local에서\n",
    "    - raw tokenizer -> model -> 결과값 (logits(각 결과와 확률)) -> 예측값 출력\n",
    "    \n",
    "```\n",
    "허깅 페이스 transformers에서 지원하는 task\n",
    "\"sentiment-analysis\" : \"text-classification\"의 별칭 (감정분석 전용으로 사용)\n",
    "\"text-classificaiton\" : 감정분석, 뉴스분류, 리뷰분류 등 분류 등 일반적인 문장 분류\n",
    "\"zero-shot-classification\" : 레이블을 학습 없이 주어진 후보군 중에서 분류\n",
    "\"token-classificaiton\" : 개체명 인식(NER : Name Entity Recognition) 등 단위 라벨링\n",
    "\"ner\" : \"token-classification\"의 별칭\n",
    "\"text-generation\" : 텍스트 생성 (GPT류 모델에 사용)\n",
    "\"text2text-generation\" : 번역, 요약 등 입력 -> 출력변환\n",
    "\"translation\" : 번역\n",
    "\"summarization\" : 텍스트 요약\n",
    "\"image-to-text\" : 그림 설명\n",
    "\"image-classification\" : 이미지 분류\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80d9df4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import logging\n",
    "# 경고 제거\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# transformers 로깅 레벨 조정\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "# Hugging Face symlink 경고 제거\n",
    "os.environ['HF_HUB_DISABLE_SYMLINKS_WARNING'] = '1'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# from transformers import pipeline, logging as hf_logging\n",
    "# hf_logging.set_verbosity_error()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0910462",
   "metadata": {},
   "source": [
    "# 1. 텍스트 기반 감정분석(긍정/부정)\n",
    "- C:/사용자/컴퓨터명/.cache/huggingface/hub/모델이름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bbd6c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598049521446228}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(task=\"sentiment-analysis\")\n",
    "classifier(\"I've been waiting for a HuggingFace course my whole life.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78bb4181",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598049521446228},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(task=\"text-classification\", model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "classifier([\"I've been waiting for a HuggingFace course my whole life.\", \"I hate this so much!\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f39e0c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.857815682888031},\n",
       " {'label': 'POSITIVE', 'score': 0.9998776912689209}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier([\"이 영화 정말 최고였어요. 감동적이고 연기가 대단해\", \n",
    "            \"This was the best movie. It was touching and the acting is amazing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3716efce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998695850372314},\n",
       " {'label': 'NEGATIVE', 'score': 0.9991129040718079},\n",
       " {'label': 'NEGATIVE', 'score': 0.5795602202415466},\n",
       " {'label': 'POSITIVE', 'score': 0.8669533729553223}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier([\"I like you\", \"I hate you\", \"나 너 싫어\", \"힘들어요\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96b1b306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(task=\"sentiment-analysis\",\n",
    "                     model=\"matthewburke/korean_sentiment\")\n",
    "texts = ['나는 너가 좋아', \"당신이 싫어요\", \"힘들어요\", \"오늘 기분이 최고야\"]\n",
    "result = classifier(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0361d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나는 너가 좋아 => 긍정 : 0.9558\n",
      "당신이 싫어요 => 부정 : 0.9093\n",
      "힘들어요 => 부정 : 0.9140\n",
      "오늘 기분이 최고야 => 긍정 : 0.9714\n"
     ]
    }
   ],
   "source": [
    "for text, result in zip(texts, classifier(texts)):\n",
    "    label = \"긍정\" if result['label']=='LABEL_1' else \"부정\"\n",
    "    print(f\"{text} => {label} : {result['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455716c0",
   "metadata": {},
   "source": [
    "# 2. 제로샷분류(Zero-shot)분류\n",
    "- 기계학습 및 자연어처리에서 각 개별 작업에 대한 특정 교육없이 작업을 수행할수 있는 모형(비지도학습)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffad2936",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'I have a problem with my iphone that needs to be resolved asap!',\n",
       " 'labels': ['urgent', 'phone', 'computer', 'not urgent', 'tablet'],\n",
       " 'scores': [0.5227580070495605,\n",
       "  0.45814019441604614,\n",
       "  0.0142647260800004,\n",
       "  0.0026850001886487007,\n",
       "  0.002152054337784648]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "classifier(\n",
    "    \"I have a problem with my iphone that needs to be resolved asap!\",\n",
    "    candidate_labels=[\"urgent\", \"not urgent\", \"phone\", \"tablet\", \"computer\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52ea889d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'One day I well see the world',\n",
       " 'labels': ['travel', 'cooking', 'dancing'],\n",
       " 'scores': [0.9938077926635742, 0.003099897177889943, 0.003092351369559765]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_to_classify = \"One day I well see the world\"\n",
    "candidate_labels = ['travel', 'cooking', 'dancing']\n",
    "classifier(sequence_to_classify, candidate_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161b1b85",
   "metadata": {},
   "source": [
    "# 3. text 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1884fe77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'in this cotokenizer. We will teach you how to create a cotokenizer as well as to make your own. First you need to make a new cotokenizer. Choose your favorite cotokenizer, or you can choose from our 5 favorite cotokenizers and place them in our category. Then you can put a text in your cotokenizer and use that text to create a new cotokenizer. If you want to add a new cotokenizer and place it next to your favorite cotokenizer, choose the option \"Add to your category\" and add the text you want and then choose \"Copy to folder\".\\n\\nThe cotokenizer will have a folder in the background with your favorite text and a folder in the center that will contain your favorite cotokenizer.\\n\\nMake the cotokenizer.\\n\\nStep-by-step instructions for creating and using this cotokenizer\\n\\n1. In the cotokenizer, copy and paste the text you want to create and paste the text into your text editor.\\n\\n2. In the text editor, edit the lines.\\n\\n3. In the text editor, copy and paste the text you want to copy and paste into your text editor.\\n\\n4. In'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "generation = pipeline(\"text-generation\", \"gpt2\") # 텍스트 생성 gpt3부터는 허깅페이스에 없음\n",
    "generation(\n",
    "    \"in this cotokenizer. We will teach you how to\",\n",
    "    pad_token_id=generation.tokenizer.eos_token_id\n",
    ") # pad_token_id 경고를 없애려고 setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49db42d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in this course. We will teach you how to use an HTML5/CSS3 library to create your own web applications.\n",
      "\n",
      "The course is also available as an online course.\n",
      "\n",
      "Course Features\n",
      "\n",
      "Course Overview\n",
      "\n",
      "The course is designed to teach you the basics of Web application development. This course is designed to teach you how to write HTML5 applications in Go.\n",
      "\n",
      "Learning Objective-C for Web Applications\n",
      "\n",
      "This course provides an easy way for you to learn Objective-C in Go, while still learning Objective-C for Web Applications. We will cover:\n",
      "\n",
      "HTML5 development (using the Go library)\n",
      "\n",
      "The concepts and tools of the library\n",
      "\n",
      "The Go documentation\n",
      "\n",
      "How to create a web application in Go\n",
      "\n",
      "What the library does\n",
      "\n",
      "The course will demonstrate the basic concepts and tools of the library, while also providing you with a demonstration of the underlying Go implementation.\n",
      "\n",
      "Note: Students must be familiar with Go. It is recommended that students have access to Go 4.2 or below.\n",
      "\n",
      "What the Go Library Does\n",
      "\n",
      "The library creates a Go server that handles all the HTTP requests to and from an application. It also creates a Go resource for handling the responses.\n",
      "\n",
      "The library is also able to handle the creation of data in the\n"
     ]
    }
   ],
   "source": [
    "result = generation(\n",
    "    \"in this course. We will teach you how to\",\n",
    "    pad_token_id=generation.tokenizer.eos_token_id\n",
    ")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4ac8c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 과정은 다음과 같은 방법을 알려드려요~\n",
      "1. 모든 사람이 동의한다.\n",
      "2. 이 절차를 통해 얻은 정보가 얼마나 유용할까?\n",
      "3. 그 정보는 어떤 방식으로 입수하고 어디에서 무엇을 얻었는지 구체적으로 설명되지 않는다.\n",
      "4. 다른 사람의 아이디어는 어느 날 어떤 곳에서 입수했고 어떤 분야에서 더 많은 이익을 얻고 더 많이 얻은 것이 있을까?\n",
      "5. 모든 사람들에게 얼마나 많은 것을 얻기 위해서 얼마나 노력했는지를 알려준다.\n",
      "6. 우리는 다른 사람과 똑같은 정보를 입수했는지 궁금해지는가?\n",
      "7. 그들은 자신의 아이디어와 관련한 정보를 습득해 왔는지?\n",
      "8. 다른 사람들의 아이디어, 특히 사람들이\n"
     ]
    }
   ],
   "source": [
    "generation = pipeline(\"text-generation\", \"skt/kogpt2-base-v2\")\n",
    "result = generation(\n",
    "    \"이 과정은 다음과 같은 방법을 알려드려요\",\n",
    "    pad_token_id=generation.tokenizer.eos_token_id,\n",
    "    max_new_tokens = 100, # 생성할 최대 길이 (생성할 토큰 수)\n",
    "    num_return_sequences=1, # 생성할 문장 갯수 \n",
    "    do_sample=True, # 다양한 샘플 사용\n",
    "    top_k=50, # top-k 샘플링(확률 높은 사위 50개 토큰만 사용)\n",
    "    top_p=0.95, # 확률이 높은 순서대로 95%될 때까지의 단어들로만 후보로 사용\n",
    "    temperature=1.2, # 창의성 조절 (낮을수록 보수적)\n",
    "    no_repeat_ngram_size=2 #반복 방지\n",
    ")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a028b1",
   "metadata": {},
   "source": [
    "# 4. 마스크(빈칸) 채우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b53ffa74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "709cdb0d6df246ccade78dc2781f8baf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b023942619643a28a9e5de8b2222c79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/331M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f56bf4ef15a447e9aa24d1235d61468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "305b394ae8aa499b97d262611e8f4e61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "877c5866460547bab49c9d257accb383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8ad3ef39b2d43e8bd29d80e8fa5a52f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.19275707006454468,\n",
       "  'token': 3299,\n",
       "  'token_str': ' doctor',\n",
       "  'sequence': \"I'm going to hospital and meet a doctor\"},\n",
       " {'score': 0.06794589757919312,\n",
       "  'token': 27321,\n",
       "  'token_str': ' psychiatrist',\n",
       "  'sequence': \"I'm going to hospital and meet a psychiatrist\"}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "unmasker = pipeline(task='fill-mask', model='distilbert/distilroberta-base') #마스크 채우기\n",
    "unmasker(\"I'm going to hospital and meet a <mask>\", top_k=2) # top_k 기본값 : 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b952367d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.2594446539878845,\n",
       "  'token': 1437,\n",
       "  'token_str': ' ',\n",
       "  'sequence': '안녕하세요! 나는 모델이에요'},\n",
       " {'score': 0.14142775535583496,\n",
       "  'token': 12,\n",
       "  'token_str': '-',\n",
       "  'sequence': '안녕하세요! 나는-모델이에요'},\n",
       " {'score': 0.09121906757354736,\n",
       "  'token': 34437,\n",
       "  'token_str': '~',\n",
       "  'sequence': '안녕하세요! 나는~모델이에요'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker('안녕하세요! 나는 <mask>모델이에요', top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61a632bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google-bert/bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.1441437155008316,\n",
       "  'token': 2535,\n",
       "  'token_str': 'role',\n",
       "  'sequence': \"hello, i ' m a role model.\"},\n",
       " {'score': 0.14175789058208466,\n",
       "  'token': 4827,\n",
       "  'token_str': 'fashion',\n",
       "  'sequence': \"hello, i ' m a fashion model.\"},\n",
       " {'score': 0.062214579433202744,\n",
       "  'token': 2047,\n",
       "  'token_str': 'new',\n",
       "  'sequence': \"hello, i ' m a new model.\"},\n",
       " {'score': 0.041028350591659546,\n",
       "  'token': 3565,\n",
       "  'token_str': 'super',\n",
       "  'sequence': \"hello, i ' m a super model.\"},\n",
       " {'score': 0.025911200791597366,\n",
       "  'token': 2449,\n",
       "  'token_str': 'business',\n",
       "  'sequence': \"hello, i ' m a business model.\"}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker = pipeline(task='fill-mask', model='google-bert/bert-base-uncased')\n",
    "unmasker(\"Hello, I'm a [MASK] model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6e0e49",
   "metadata": {},
   "source": [
    "## ※ Inference API 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "657a40e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "# os.environ['HF_TOKEN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224a68e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-dl-nlp(ipykernel)",
   "language": "python",
   "name": "ml-dl-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
