{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21698f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.container{width:90% !important;}\n",
       "div.cell.code_cell.rendered{width:100%;}\n",
       "div.input_prompt{padding:0px;}\n",
       "div.CodeMirror {font-family:Consolas; font-size:12pt;}\n",
       "div.text_cell_render.rendered_html{font size:12pt;}\n",
       "div.output {font-size:12pt; font-weight:bold;}\n",
       "div.input{font-family:Consolas; font-size:12pt;}\n",
       "div.prompt {min width:70px;}\n",
       "div#toc-wrapper {padding-top:120px;}\n",
       "div.text_cell_render ul li{font-size:12pt;padding:5px;}\n",
       "table.dataframe {font-size:12px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "div.container{width:90% !important;}\n",
    "div.cell.code_cell.rendered{width:100%;}\n",
    "div.input_prompt{padding:0px;}\n",
    "div.CodeMirror {font-family:Consolas; font-size:12pt;}\n",
    "div.text_cell_render.rendered_html{font size:12pt;}\n",
    "div.output {font-size:12pt; font-weight:bold;}\n",
    "div.input{font-family:Consolas; font-size:12pt;}\n",
    "div.prompt {min width:70px;}\n",
    "div#toc-wrapper {padding-top:120px;}\n",
    "div.text_cell_render ul li{font-size:12pt;padding:5px;}\n",
    "table.dataframe {font-size:12px;}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea024bd",
   "metadata": {},
   "source": [
    "<font size='6' color='red'><b>ch2 Ollama LLM활용의 기본개념(LangChain)</b></font>\n",
    "# 1. LLM을 활용하여 답변 생성하기\n",
    "## 1) Ollama를 이용한 로컬 LLM 이용\n",
    "- 성능은 GPT, CLaude 같은 모델보다 떨어지나, 개념설명을 위해 open source 모델 사용\n",
    "\n",
    "### ollama.com 다운로드 -> 설치 -> 모델 pull\n",
    "- cmd 창이나 powershell 창에 ollama run deepseek-r1:1.5b\n",
    "https://docs.langchain.com/oss/python/integrations/chat/ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7ec9393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of Korea is釜山.', additional_kwargs={}, response_metadata={'model': 'deepseek-r1:1.5b', 'created_at': '2025-12-09T02:05:46.3893471Z', 'done': True, 'done_reason': 'stop', 'total_duration': 546340700, 'load_duration': 87427200, 'prompt_eval_count': 10, 'prompt_eval_duration': 63311400, 'eval_count': 13, 'eval_duration': 382803700, 'logprobs': None, 'model_name': 'deepseek-r1:1.5b', 'model_provider': 'ollama'}, id='lc_run--019b00db-87f1-71c3-bb2b-0992cb31782c-0', usage_metadata={'input_tokens': 10, 'output_tokens': 13, 'total_tokens': 23})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"deepseek-r1:1.5b\")\n",
    "result = llm.invoke(\"What is the capital of Korea?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e747dcf6",
   "metadata": {},
   "source": [
    "### 모델 pull\n",
    "- cmd나 powershell 창에서 : ollama pull llama3.2:1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2138cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"The capital of South Korea is Seoul. However, it's worth noting that North Korea also claims Seoul as its own capital, and many Koreans consider Mount Myohyang in North Korea to be their capital. But officially, Seoul remains the capital of South Korea.\", additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-12-09T02:20:16.0904082Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3464817700, 'load_duration': 1272672500, 'prompt_eval_count': 32, 'prompt_eval_duration': 224774200, 'eval_count': 53, 'eval_duration': 1909547700, 'logprobs': None, 'model_name': 'llama3.2:1b', 'model_provider': 'ollama'}, id='lc_run--019b00e8-c1d1-79b2-bb15-927b7267aa58-0', usage_metadata={'input_tokens': 32, 'output_tokens': 53, 'total_tokens': 85})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model='llama3.2:1b')\n",
    "result = llm.invoke(\"What is the capital of Korea?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b468b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The capital of South Korea is Seoul. However, it's worth noting that North Korea also claims Seoul as its own capital, and many Koreans consider Mount Myohyang in North Korea to be their capital. But officially, Seoul remains the capital of South Korea.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "922098cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'한국의 수도는 Seoul입니다. 유한공리 church를 포함하여 한국에서 가장 큰 수도지로, 세계적으로 유명합니다.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = llm.invoke(\"한국 수도가 어디에요?\")\n",
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638dcbde",
   "metadata": {},
   "source": [
    "## 2) openai 활용\n",
    "- pip install langchain-openai\n",
    "- https://auth.openai.com/log-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27cb12e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 환경변수 가져오기\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fde5e2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-5-nano\",\n",
    "                #api_key=os.getenv(\"OPENAI_API_KEY\") # api key를 OPENAI_API_KEY로 하지 않을경우에는 api_key를 지정해야한다\n",
    "                )\n",
    "result = llm.invoke(\"What is the capital of Korea? Return the name of the city only.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22e5ddd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Seoul', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 395, 'prompt_tokens': 21, 'total_tokens': 416, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 384, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CkkVyqbukGrnGYj4D3GEBaayuJqwI', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b0192-525c-79c2-b92d-4c8d6b238007-0', usage_metadata={'input_tokens': 21, 'output_tokens': 395, 'total_tokens': 416, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 384}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471823d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure : OPENAI_API_VERSION키 값\n",
    "# from langchain_openai import AzureOpenAI\n",
    "# llm = AzureOpenAI(model=\"gpt-5-nano\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c592c0a7",
   "metadata": {},
   "source": [
    "# 2. 랭체인 스타일로 프롬포트 작성\n",
    "- 프롬프트  llm 호출시 쓰는 질문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25461416",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"llama3.2:1b\")\n",
    "#llm.invoke(0)\n",
    "# 프롬프트로의 종류 : PromptValue, str, BaseMessages 리스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bb4273",
   "metadata": {},
   "source": [
    "## 1) 기본 프롬프트 템플릿 사용\n",
    "- PromptTemplate을 사용하여 변수가 포함된 템플릿을 작성하면 PromptValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77fecc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어느 나라의 수도를 알고 싶으신가요?\n",
      "text='What is the capital of ?'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Could you please provide more context or specify which country or location you're asking about? I'll do my best to provide the correct information.\", additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-12-09T05:47:50.4240093Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1388801000, 'load_duration': 145781900, 'prompt_eval_count': 31, 'prompt_eval_duration': 162118400, 'eval_count': 29, 'eval_duration': 1049106200, 'logprobs': None, 'model_name': 'llama3.2:1b', 'model_provider': 'ollama'}, id='lc_run--019b01a6-d3a9-7e11-8043-487e21ba9e78-0', usage_metadata={'input_tokens': 31, 'output_tokens': 29, 'total_tokens': 60})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"What is the capital of {country}?\", # {}안의 값을 새로운 값으로 대입 가능\n",
    "    input_variables=[\"country\"]\n",
    ")\n",
    "country = input('어느 나라의 수도를 알고 싶으신가요?')\n",
    "prompt = prompt_template.invoke({\"country\":country})\n",
    "print(prompt)\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d47d2f",
   "metadata": {},
   "source": [
    "## 2) 메세지 기반 프롬프트 작성\n",
    "- BaseMessage 리스트\n",
    "- BaseMessage 상속받은 클래스 : AIMessage, HumanMessage, SystemMessage, ToolMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06ff91fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of the United Kingdom, which includes England, is London.', additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-12-09T06:12:33.3535489Z', 'done': True, 'done_reason': 'stop', 'total_duration': 841669300, 'load_duration': 157178900, 'prompt_eval_count': 182, 'prompt_eval_duration': 122316100, 'eval_count': 15, 'eval_duration': 541368700, 'logprobs': None, 'model_name': 'llama3.2:1b', 'model_provider': 'ollama'}, id='lc_run--019b01bd-767d-7df2-8a00-1ddc91936563-0', usage_metadata={'input_tokens': 182, 'output_tokens': 15, 'total_tokens': 197})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"llama3.2:1b\")\n",
    "message_list = [\n",
    "    SystemMessage(content=\"You are a helpful assistant!\"), # 페르소나 부여\n",
    "    HumanMessage(content=\"What is the capital of Italy?\"), # 모범질문\n",
    "    AIMessage(content=\"The capital of Italy is Rome.\"), # 모범질문에 대한 모범답안\n",
    "    HumanMessage(content=\"What is the capital of France?\"), # 모범질문\n",
    "    AIMessage(content=\"The capital of France is Paris.\"), # 모범질문에 대한 모범답안\n",
    "    HumanMessage(content=\"What is the capital of Japan?\"), # 모범질문\n",
    "    AIMessage(content=\"The capital of Italy is Tokyo.\"), # 모범질문에 대한 모범답안\n",
    "    HumanMessage(content=\"What is the capital of China?\"), # 모범질문\n",
    "    AIMessage(content=\"The capital of France is Beijing.\"), # 모범질문에 대한 모범답안\n",
    "    HumanMessage(content=\"What is the capital of USA?\"), # 모범질문\n",
    "    AIMessage(content=\"The capital of Italy is Washington.\"), # 모범질문에 대한 모범답안\n",
    "    HumanMessage(content=\"What is the capital of Canada?\"), # 모범질문\n",
    "    AIMessage(content=\"The capital of France is Ottawa.\"), # 모범질문에 대한 모범답안\n",
    "    HumanMessage(content=\"What is the capital of England?\")\n",
    "]\n",
    "llm.invoke(message_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bcab68",
   "metadata": {},
   "source": [
    "## 3) ChatPromptTemplate 사용\n",
    "- BaseMessage리스트 -> 튜플리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2056221b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어느 나라 수도가 궁금하세요Korea\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The capital of South Korea is Seoul. The capital of North Korea is Pyongyang.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 위의 BaseMessage 리스트를 수정\n",
    "# PromptTemplate : 프롬프트에 변수포함,\n",
    "# ChatPromptTemplate : SystemPrompt설정(페르소나), few shot 설정, 변수포함\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "chatPrompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant!\"),\n",
    "    (\"human\", \"What is the capital of Italy?\"),\n",
    "    (\"ai\", \"The capital of Italy is Rome.\"),\n",
    "    (\"human\", \"What is the capital of France?\"),\n",
    "    (\"ai\", \"The capital of France is Paris.\"),\n",
    "    (\"human\", \"What is the capital of {country}?\")\n",
    "])\n",
    "\n",
    "country = input(\"어느 나라 수도가 궁금하세요\")\n",
    "prompt = chatPrompt_template.invoke({\"country\": country})\n",
    "# print('프롬프트 :', prompt, type(prompt))\n",
    "result = llm.invoke(prompt)\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c74d6e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어느나라 수도가 궁금하세요?한국\n",
      "한국의 수도는 Seoul로, 동서부에서 서北부를 통과하여 동쪽으로 방향을 가는 방정식으로 38° 37' north latitude와 126° 58' east longitude입니다.\n"
     ]
    }
   ],
   "source": [
    "chatPrompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 대한민국 정보 전문 도우미입니다\"),\n",
    "    (\"human\", \"{country}의 수도는 어디에요?\")\n",
    "])\n",
    "country = input(\"어느나라 수도가 궁금하세요?\")\n",
    "prompt = chatPrompt_template.invoke({\"country\" : country})\n",
    "# print(prompt)\n",
    "result = llm.invoke(prompt)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd2af14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"한국의 수도는 Seoul로, 동서부에서 서北부를 통과하여 동쪽으로 방향을 가는 방정식으로 38° 37' north latitude와 126° 58' east longitude입니다.\", additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-12-09T06:39:18.7509432Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2176248500, 'load_duration': 103250600, 'prompt_eval_count': 43, 'prompt_eval_duration': 168863100, 'eval_count': 50, 'eval_duration': 1850130200, 'logprobs': None, 'model_name': 'llama3.2:1b', 'model_provider': 'ollama'}, id='lc_run--019b01d5-f05e-7791-801f-2a3e155d6d0a-0', usage_metadata={'input_tokens': 43, 'output_tokens': 50, 'total_tokens': 93})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd8d600",
   "metadata": {},
   "source": [
    "# 3. 답변 형식 컨트롤하기\n",
    "- llm.invoke()의 결과는 AIMessage() -> string이나 json, 객체 : OutputParser이용\n",
    "\n",
    "## 1) 문자열 출력 파서 이용\n",
    "- StrOutputParser를 사용하여 LLM 출력(AIMessage)를 단순 문자열로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54511e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "# 명시적인 지시사항이 포함된 프롬프트\n",
    "prompt_template = PromptTemplate(\n",
    "    template = \"What is the capital of {country}. Return the name of the city only\",\n",
    "    input_variables = [\"country\"]\n",
    ")\n",
    "\n",
    "# 프롬프트 템플릿에 값 주입\n",
    "prompt = prompt_template.invoke({\"country\" : \"Korea\"})\n",
    "ai_message = llm.invoke(prompt)\n",
    "# ai_message\n",
    "#문자열 출력 파서를 이용하여 llm응답(AIMessage 객체)을 단순 문자열로 변환\n",
    "output_parse = StrOutputParser()\n",
    "result = output_parse.invoke(ai_message)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5d1ec1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parse.invoke(llm.invoke(prompt_template.invoke({\"country\":\"Korea\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35fac32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 변수설정, system, few shot 지정\n",
    "chat_prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful assistant with expertise in South Korea\"),\n",
    "    (\"human\", \"What is the capital of Italy?\"),\n",
    "    (\"ai\", \"Rome.\"),\n",
    "    (\"human\", \"What is the capital of France?\"),\n",
    "    (\"ai\", \"Paris.\"),\n",
    "    (\"human\", \"What is the capital of {country}?\")\n",
    "])\n",
    "\n",
    "output_parse = StrOutputParser()\n",
    "output_parse.invoke(llm.invoke(prompt_template.invoke({\"country\":\"Korea\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc8e673",
   "metadata": {},
   "source": [
    "## 2) Json 파서 이용\n",
    "- {'name':'홍길동', 'age':22}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7d3bdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'capital': 'Seoul', 'population': 51000000, 'language': 'Korean', 'currency': 'South Korean won'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "country_detail_prompt = PromptTemplate(\n",
    "    template = \"\"\" Give following information about {country}.\n",
    "    - Capital\n",
    "    - Population\n",
    "    - Language\n",
    "    - Currency\n",
    "    Return in JSON format and Json dictionary only\n",
    "    \"\"\",\n",
    "    input_variables=[\"country\"]\n",
    ")\n",
    "prompt = country_detail_prompt.invoke({\"country\":\"Korea\"})\n",
    "ai_message = llm.invoke(prompt)\n",
    "# print(ai_message.content)\n",
    "output_parser = JsonOutputParser()\n",
    "json_result = output_parser.invoke(ai_message)\n",
    "print(json_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1faba1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Japan',\n",
       " 'capital': 'Tokyo',\n",
       " 'population': 128768500,\n",
       " 'language': 'Japanese',\n",
       " 'currency': {'symbol': '$', 'code': 'JPY'}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.invoke(llm.invoke(country_detail_prompt.invoke({\"country\":\"Japan\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c9ebaa",
   "metadata": {},
   "source": [
    "## 3) 구조화된 출력 사용\n",
    "- Pydantic 모델을 사용하여 LLM 출력을 구조화된 형식으로 받기 (JsonParser 보다 훨씬 안정적)\n",
    "- Pydantic : 데이터 유효성검사, 설정관리를 간편하게 해주는 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c636f7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.User object at 0x00000216090149A0>\n"
     ]
    }
   ],
   "source": [
    "class User:\n",
    "    def __init__(self, id_, name, is_active=True):\n",
    "        self.id_ = id_\n",
    "        self.name = name\n",
    "        self.is_active = is_active\n",
    "user = User(1, '홍길동')\n",
    "print(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "267d93d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id=1 name='홍길동' is_active=True\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "class User(BaseModel):\n",
    "    id:int = Field(gt=0, description=\"id\")\n",
    "    name:str = Field(min_length=2, description=\"name\")\n",
    "    is_active:bool = Field(default=True, description=\"id 활성화 여부\")\n",
    "user = User(id=1, name='홍길동')\n",
    "print(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a49790a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountryDetail(capital='Seoul', population=51, language='Korean', currency='South Korean won')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_detail_prompt = PromptTemplate(\n",
    "    template = \"\"\" Give following information about {country}.\n",
    "    - Capital\n",
    "    - Population\n",
    "    - Language\n",
    "    - Currency\n",
    "    Return in JSON format and Json dictionary only\n",
    "    \"\"\",\n",
    "    input_variables=[\"country\"]\n",
    ")\n",
    "class CountryDetail(BaseModel): # description : 더 정확한 출력 유도\n",
    "    capital:str = Field(description=\"the Capital of the country\")\n",
    "    population:int = Field(description=\"the population of the country\")\n",
    "    language:str = Field(description=\"the language of the country\")\n",
    "    currency:str = Field(description=\"the currency of the country\")\n",
    "structuredllm = llm.with_structured_output(CountryDetail)\n",
    "info = structuredllm.invoke(country_detail_prompt.invoke({\"country\":\"Korea\"}))\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b36028b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Seoul', 51, 'Korean', 'South Korean won')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.capital, info.population, info.language, info.currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2893b7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info를 json으로 : {\"capital\":\"Seoul\",\"population\":51,\"language\":\"Korean\",\"currency\":\"South Korean won\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"info를 json으로 :\", info.model_dump_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f8ced5",
   "metadata": {},
   "source": [
    "# 4. LCEL을 활용한 렝체인 생성하기\n",
    "## 1) 문자열 출력 파서 사용\n",
    "- invoke\n",
    "- StrOutputParser, ChatOllama, PromptTemplate등은 모두 XXX로 상속"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a7cf2d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2:1b\",\n",
    "                temperature=0) # 일관된 답변(보수적인 답변)\n",
    "prompt_template = PromptTemplate(\n",
    "    template = \"What is the capital of {country}. Retrun the name of the city only.\",\n",
    "    input_variables = [\"country\"]\n",
    ")\n",
    "output_parser = StrOutputParser() # AIMessage()를 Str변환\n",
    "output_parser.invoke(llm.invoke(prompt_template.invoke({\"country\":\"Korea\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807f4cfb",
   "metadata": {},
   "source": [
    "## 2) LCEL을 사용한 간단한 체인 구성\n",
    "- 파이프 연산자(|) 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6b4dd133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 프롬프트 템플릿 -> llm -> 출력파서를 연결하는 체인 생성\n",
    "capital_chain = prompt_template | llm | output_parser\n",
    "# 생성된 체인 invoke\n",
    "capital_chain.invoke({\"country\":\"Korea\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c665394",
   "metadata": {},
   "source": [
    "## 3) 복합체인 구성\n",
    "- 여러 단계의 추론이 필요한 경우 (체인 연결)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "551604d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Canada.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 나라 설명 -> 나라 이름\n",
    "country_prompt = PromptTemplate(\n",
    "template = \"\"\" Guess the name of the country based on the following information:\n",
    "    {information}\n",
    "    Return the name of the country only\"\"\",\n",
    "    input_variables=[\"information\"])\n",
    "output_parser.invoke(llm.invoke(country_prompt.invoke({\"information\": \"Known for maple leaf\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8613386f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Canada.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 나라명 추출 체인 생성\n",
    "country_chain = country_prompt | llm | output_parser\n",
    "country_chain.invoke({\"information\": \"Known for maple leaf\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6ac4483f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ottawa'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 복합체인 : 나라설명 -> 나라명 (country_chain)\n",
    "#                     나라명 -> 수도 (capital chain)\n",
    "final_chain = country_chain | capital_chain\n",
    "final_chain.invoke({\"information\": \"Known for maple leaf\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bf4d6cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 복합체인 : information -> country_chain -> (나라명을 country) -> capital_chain\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "final_chain = {\"information\":RunnablePassthrough()} | {\"country\":country_chain} | capital_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9b1fb4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ottawa'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain.invoke(\"Known for maple leaf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc39a995",
   "metadata": {},
   "source": [
    "- 한글지원 여부 (한글 지원이 안 되는 모델은 렝체인 연결이 잘 안 됨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "505227b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'이 나라는 와인으로 유명해\\n\\n1. 프랑스 - burgundy, merlot, cabernet sauvignon\\n2. 이탈리아 - chianti, pinot noir, vermentino\\n3. 스타일러 - merlot, shiraz, syrah\\n4. 이스라엘 - merlot, cabernet sauvignon, pinot noir\\n5. 미국 - merlot, cabernet sauvignon, pinot noir'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 나라 설명 -> 나라이름\n",
    "country_prompt = PromptTemplate(\n",
    "    template=\"\"\"다음의 {information} 설명을 보고 나라이름을 맞춰봐:\n",
    "    {information}\n",
    "    나라 이름만 한국어로 reutrn 해 줘\"\"\",\n",
    "    input_variables=[\"information\"]\n",
    ")\n",
    "output_parser.invoke(llm.invoke(country_prompt.invoke({\"information\":\n",
    "                            \"이 나라는 와인으로 유명해\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4770cc",
   "metadata": {},
   "source": [
    "# 5. 생성형 AI 평가 (생성형_AI.ipynb):\n",
    "- 위 : 나라설명->나라이름->수도 (체인2개연결)\n",
    "- 나라이름 -> 음식 -> 레시피"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12953c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 복합체인 : 나라명 -> 그 나라에서 제일 유명한 음식 (food_chain)\n",
    "                    # 음식 -> 레시피 (recipe_chain)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm(ipykernel)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
