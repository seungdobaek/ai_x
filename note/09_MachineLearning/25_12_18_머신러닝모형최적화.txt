4장 머신러닝 모형 최적화
 1절 변수 선택과 차원 축소
  1-1 변수선택과 차원축소
	종속변수에 영향을 주는 변수들을 찾아 학습에 사용할 독립변수의 수를 줄임
	과적합과 변수들 사이의 다중공선성(변수들간 강한 상관관계)을 줄일 수 있음
	모형의 학습 시간을 줄일 수 있음
  1-2 주성분분석(PCA, Principal Component Anaysis)
	 변수 선택 및 차원축소 방법(기존의 모든 변수를 조합하여 새로운 변수로 만듦) 으로 널리 사용
	상관관계가 있는 변수들을 선형결합해서 분산이 극대화된 상관관계가 없는 새로운 변수(주성분) 들로 축약하는 것
  1-3 상관관계 확인 : 각 변수들끼리 상관관계를 확인하고 시각화해서 종속변수와 상관관계각 높은 변수들만 선택
  1-4 분류모형의 Feature Importance
	feature_importance_ 속성 : 각 독립변수들의 종속변수에 영향을 주는 정도
	RFE (Recursive Feature Elimination) 방식
		RFE를 이용하며 중요도에 따라 중요도가 낮은 변수부터 하나씩 제거해 나가면서 최종적으로 선택한 변수를 찾는다
  1-5 SelectKBest : 가장 높은 score에 따라 k개 특징변수 선택
 2절 파라미터 탐색
	하이퍼 파라미터 : 모델의 성능에 영향을 미칠수 있는 사용자가 직접 설정하는 파라미터
	어떤 파라미터를 사용하는게 최적의 결과를 낼지 탐색
  2-1 validation_curve : 모형, 데이터(독립, 종속), 파라미터 이름, 파라미터 값 리스트, 교차검증, scoring기준
  2-2 GridSearchCV : 복수 hyperparameter 최적화 클래스
 3절 자료 불균형 처리
	단순 오버/언더 샘플링
		단, 단순 오버샘플시 소스의 데이터를 복사하면 그 데이터들에 의해 과적합이 생길 수 있음
  3-1 SMOTE를 이용한 오버샘플링
  3-2 가중치 제어 모형 : 모델에 데이터 따른 가중치 부여 방법
 4절 앙상블 모형
	여러개 분류 모델을 하나의 통합 분류모델로 연결하여 개별 분류모델보다 더 좋은 성능 달성
	방법 3개 (배깅, 부스팅, 투표)
	배깅 : 분류를 잘하는 모델에 가중치 (병렬작업) ex) RandomForest
	부스팅 : 분류가 안된 데이터에 가중치(순차작업) ex) XGBoost, LGBM, AdaBoost - 불균형 데이터에 적합
	투표 : 여러개 모델의 다수결 투표