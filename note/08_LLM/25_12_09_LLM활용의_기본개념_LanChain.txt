2장 LLM활용의 기본개념 (Ollama, Langchain)
 1절 LLM을 활용하여 답변 생성하기
	Ollama를 이용한 로컬 LLM 이용
		ollama.com 다운로드 -> 설치 -> 모델 pull
 2절 랭체인 스타일로 프롬포트 작성
	프롬프트 : llm 호출시 쓰는 질문
  1) 기본 프롬프트 템플릿 사용
	PromptTemplate을 사용하여 변수가 포함된 템플릿을 작성하면 PromptValue
  2) 메세지 기반 프롬프트 작성
	BaseMessage 리스트 사용
	BaseMessage 상속받은 클래스 : AIMessage, HumanMessage, SystemMessage, ToolMessage
  3) ChatPromptTemplate 사용
	BaseMessage와 거의 동일하지만 튜플리스트로 사용
 3절 답변 형식 컨트롤하기
	llm.invoke()의 결과는 AIMessage() -> string이나 json, 객체 : OutputParser이용
  1) 문자열 출력 파서 이용
	StrOutputParser를 사용하여 LLM 출력(AIMessage)를 단순 문자열로 변환
  2) Json 파서 이용
  3) 구조화된 출력 사용
	Pydantic 모델을 사용하여 LLM 출력을 구조화된 형식으로 받기 (JsonParser 보다 훨씬 안정적)
	Pydantic : 데이터 유효성검사, 설정관리를 간편하게 해주는 라이브러리
 4절 LCEL을 활용한 렝체인 생성하기
  1) 문자열 출력 파서 사용
  2) LCEL을 사용한 간단한 체인 구성
	파이프 연산자(|) 이용
  3) 복합체인 구성